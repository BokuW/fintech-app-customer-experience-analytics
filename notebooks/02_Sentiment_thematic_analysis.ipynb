{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a0231b6",
   "metadata": {},
   "outputs": [],
   "source": [
    " #notebooks/02_sentiment_thematic_analysis.ipynb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re # For regex in text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0419ddaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics' to sys.path for module imports.\n",
      "Project structure setup complete and config.py created/updated.\n",
      "Base Directory: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics\n",
      "Raw Data Directory: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics\\data\\raw\n",
      "Processed Data Directory: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics\\data\\processed\n",
      "App IDs to scrape: {'Commercial Bank of Ethiopia': 'com.combanketh.mobilebanking', 'Bank of Abyssinia': 'com.boa.boaMobileBanking', 'Dashen Bank': 'com.dashen.dashensuperapp'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Project Setup: Ensure src module is discoverable ---\n",
    "def find_project_root(current_path):\n",
    "    path = current_path\n",
    "    while path != os.path.dirname(path):\n",
    "        if (os.path.isdir(os.path.join(path, 'src')) and\n",
    "            os.path.isdir(os.path.join(path, 'data')) and\n",
    "            os.path.isdir(os.path.join(path, 'notebooks'))):\n",
    "            return path\n",
    "        path = os.path.dirname(path)\n",
    "    return current_path\n",
    "\n",
    "current_working_dir = os.getcwd()\n",
    "project_root = find_project_root(current_working_dir)\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"Added '{project_root}' to sys.path for module imports.\")\n",
    "else:\n",
    "    print(f\"'{project_root}' already in sys.path.\")\n",
    "\n",
    "# Import configuration variables\n",
    "from src.config import CLEAN_REVIEWS_CSV, PROCESSED_DATA_DIR\n",
    "\n",
    "# Define output file for Task 2 results\n",
    "SENTIMENT_THEMES_CSV = os.path.join(PROCESSED_DATA_DIR, 'reviews_with_sentiment_themes.csv')\n",
    "# Ensure the output directory exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266d2521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Cleaned Review Data ---\n",
      "Cleaned data loaded successfully from c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics\\data\\processed\\clean_play_store_reviews.csv.\n",
      "Initial DataFrame shape: (8989, 6)\n",
      "\n",
      "First 5 rows of loaded data:\n",
      "                              review_id  \\\n",
      "0  a7d1c799-ba53-4a0a-a8d6-c5400a009825   \n",
      "1  64ed5562-1758-4eb8-9291-8b6edc394118   \n",
      "2  d0c05687-ddd4-43fb-95a9-08f6358d80a2   \n",
      "3  811bf820-3529-433a-9b6d-e624fa23a16a   \n",
      "4  be2cb2ac-bbe0-4175-81c4-9f6c86afdaaa   \n",
      "\n",
      "                                         review_text  rating        date  \\\n",
      "0  A great app. It's like carrying a bank in your...       4  2025-06-07   \n",
      "1                      More than garrantty bank EBC.       4  2025-06-07   \n",
      "2  really am happy to this app it is Siple to use...       5  2025-06-07   \n",
      "3  I liked this app. But the User interface is ve...       2  2025-06-07   \n",
      "4  \"Why don’t your ATMs support account-to-accoun...       4  2025-06-06   \n",
      "\n",
      "                     bank_name       source  \n",
      "0  Commercial Bank of Ethiopia  Google Play  \n",
      "1  Commercial Bank of Ethiopia  Google Play  \n",
      "2  Commercial Bank of Ethiopia  Google Play  \n",
      "3  Commercial Bank of Ethiopia  Google Play  \n",
      "4  Commercial Bank of Ethiopia  Google Play  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 1: Load Cleaned Data ---\n",
    "print(\"\\n--- Loading Cleaned Review Data ---\")\n",
    "try:\n",
    "    df = pd.read_csv(CLEAN_REVIEWS_CSV)\n",
    "    print(f\"Cleaned data loaded successfully from {CLEAN_REVIEWS_CSV}.\")\n",
    "    print(f\"Initial DataFrame shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows of loaded data:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"CRITICAL ERROR: Cleaned data file not found at {CLEAN_REVIEWS_CSV}. Please run Task 1 first.\")\n",
    "    sys.exit(\"Exiting: Cleaned data not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Could not load cleaned data: {e}\")\n",
    "    sys.exit(\"Exiting: Cleaned data loading failed.\")\n",
    "\n",
    "if df.empty:\n",
    "    print(\"WARNING: Loaded DataFrame is empty. Skipping sentiment and thematic analysis.\")\n",
    "    sys.exit(\"Exiting: Empty DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e29473a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing NLP Preprocessing (Tokenization, Stopword Removal) ---\n",
      "Downloading NLTK data (stopwords, punkt, vader_lexicon)...\n",
      "NLTK data download complete.\n",
      "WARNING: 124 reviews became empty after NLP cleaning. They might affect analysis.\n",
      "\n",
      "First 5 rows of data with cleaned_review_text:\n",
      "                                         review_text  \\\n",
      "0  A great app. It's like carrying a bank in your...   \n",
      "1                      More than garrantty bank EBC.   \n",
      "2  really am happy to this app it is Siple to use...   \n",
      "3  I liked this app. But the User interface is ve...   \n",
      "4  \"Why don’t your ATMs support account-to-accoun...   \n",
      "\n",
      "                                 cleaned_review_text  \n",
      "0  a great app its like carrying a bank in your p...  \n",
      "1                       more than garrantty bank ebc  \n",
      "2  really am happy to this app it is siple to use...  \n",
      "3  i liked this app but the user interface is ver...  \n",
      "4  why dont your atms support accounttoaccount tr...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Step 2: NLP Preprocessing for Sentiment and Thematic Analysis ---\n",
    "print(\"\\n--- Performing NLP Preprocessing (Tokenization, Stopword Removal) ---\")\n",
    "\n",
    "# Download NLTK data\n",
    "# These commands will download the necessary data if not already present.\n",
    "# It's more robust to call nltk.download() directly without complex try-except for DownloadError\n",
    "print(\"Downloading NLTK data (stopwords, punkt, vader_lexicon)...\")\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('vader_lexicon', quiet=True)\n",
    "print(\"NLTK data download complete.\")\n",
    "\n",
    "# Initialize NLTK Stopwords and VADER Sentiment Analyzer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function for basic text cleaning (for TF-IDF and VADER)\n",
    "def clean_text_nlp(text):\n",
    "    text = str(text).lower() # Convert to string and lowercase\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE) # Remove URLs\n",
    "    text = re.sub(r'\\@w+|\\#', '', text) # Remove @mentions and hashtags\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text) # Remove numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply NLP cleaning\n",
    "df['cleaned_review_text'] = df['review_text'].apply(clean_text_nlp)\n",
    "\n",
    "# Check for reviews that might have become empty after cleaning\n",
    "empty_cleaned_reviews = df[df['cleaned_review_text'].str.strip() == '']\n",
    "if not empty_cleaned_reviews.empty:\n",
    "    print(f\"WARNING: {len(empty_cleaned_reviews)} reviews became empty after NLP cleaning. They might affect analysis.\")\n",
    "    # Option: You could fill these with a placeholder or drop them if they are too many.\n",
    "    # For now, we'll keep them but be aware.\n",
    "\n",
    "print(\"\\nFirst 5 rows of data with cleaned_review_text:\")\n",
    "print(df[['review_text', 'cleaned_review_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6938e8bb",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Vendor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58285da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Sentiment Analysis using VADER ---\n",
      "\n",
      "Sentiment Analysis Complete. First 5 rows with sentiment:\n",
      "                                         review_text  \\\n",
      "0  A great app. It's like carrying a bank in your...   \n",
      "1                      More than garrantty bank EBC.   \n",
      "2  really am happy to this app it is Siple to use...   \n",
      "3  I liked this app. But the User interface is ve...   \n",
      "4  \"Why don’t your ATMs support account-to-accoun...   \n",
      "\n",
      "                                 cleaned_review_text sentiment_label  \\\n",
      "0  a great app its like carrying a bank in your p...        positive   \n",
      "1                       more than garrantty bank ebc         neutral   \n",
      "2  really am happy to this app it is siple to use...        positive   \n",
      "3  i liked this app but the user interface is ver...        negative   \n",
      "4  why dont your atms support accounttoaccount tr...        positive   \n",
      "\n",
      "   sentiment_score  \n",
      "0           0.7650  \n",
      "1           0.0000  \n",
      "2           0.6096  \n",
      "3          -0.2980  \n",
      "4           0.0624  \n",
      "\n",
      "Aggregated Sentiment (Mean Compound Score by Bank and Rating):\n",
      "rating                              1         2         3         4         5\n",
      "bank_name                                                                    \n",
      "Bank of Abyssinia           -0.165366 -0.029835  0.157120  0.299258  0.365774\n",
      "Commercial Bank of Ethiopia -0.067117  0.022727  0.194232  0.342867  0.390699\n",
      "Dashen Bank                 -0.024624 -0.056700  0.331625  0.314742  0.527816\n",
      "\n",
      "Sentiment Distribution by Bank:\n",
      "sentiment_label              negative   neutral  positive\n",
      "bank_name                                                \n",
      "Bank of Abyssinia            0.238506  0.309387  0.452107\n",
      "Commercial Bank of Ethiopia  0.099133  0.260841  0.640027\n",
      "Dashen Bank                  0.055556  0.204444  0.740000\n"
     ]
    }
   ],
   "source": [
    "# --- Step 3: Sentiment Analysis using VADER ---\n",
    "print(\"\\n--- Performing Sentiment Analysis using VADER ---\")\n",
    "\n",
    "# Function to get VADER sentiment\n",
    "def get_vader_sentiment(text):\n",
    "    if pd.isna(text) or text.strip() == '':\n",
    "        return {'sentiment_label': 'neutral', 'sentiment_score': 0.0}\n",
    "    vs = analyzer.polarity_scores(text)\n",
    "    compound_score = vs['compound']\n",
    "\n",
    "    if compound_score >= 0.05:\n",
    "        label = 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        label = 'negative'\n",
    "    else:\n",
    "        label = 'neutral'\n",
    "    return {'sentiment_label': label, 'sentiment_score': compound_score}\n",
    "\n",
    "# Apply VADER sentiment analysis\n",
    "# Use 'cleaned_review_text' as input for sentiment analysis\n",
    "sentiment_results = df['cleaned_review_text'].apply(get_vader_sentiment)\n",
    "df = pd.concat([df, sentiment_results.apply(pd.Series)], axis=1)\n",
    "\n",
    "print(\"\\nSentiment Analysis Complete. First 5 rows with sentiment:\")\n",
    "print(df[['review_text', 'cleaned_review_text', 'sentiment_label', 'sentiment_score']].head())\n",
    "\n",
    "# Aggregate sentiment by bank and rating (as per prompt)\n",
    "print(\"\\nAggregated Sentiment (Mean Compound Score by Bank and Rating):\")\n",
    "print(df.groupby(['bank_name', 'rating'])['sentiment_score'].mean().unstack())\n",
    "\n",
    "# You can also aggregate by sentiment label\n",
    "print(\"\\nSentiment Distribution by Bank:\")\n",
    "print(df.groupby('bank_name')['sentiment_label'].value_counts(normalize=True).unstack())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c5b637",
   "metadata": {},
   "source": [
    "# Thematic Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2407e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Performing Thematic Analysis ---\n",
      "Top 10 TF-IDF keywords (overall):\n",
      "good: 964.16\n",
      "app: 581.30\n",
      "it: 394.61\n",
      "nice: 387.56\n",
      "best: 375.28\n",
      "the: 340.16\n",
      "is: 292.30\n",
      "to: 283.37\n",
      "very: 278.37\n",
      "and: 264.62\n",
      "\n",
      "Assigning themes to reviews...\n",
      "\n",
      "Thematic Analysis Complete. First 5 rows with identified themes:\n",
      "                                         review_text  \\\n",
      "0  A great app. It's like carrying a bank in your...   \n",
      "1                      More than garrantty bank EBC.   \n",
      "2  really am happy to this app it is Siple to use...   \n",
      "3  I liked this app. But the User interface is ve...   \n",
      "4  \"Why don’t your ATMs support account-to-accoun...   \n",
      "\n",
      "                               identified_themes_str  \n",
      "0                                      Miscellaneous  \n",
      "1                                      Miscellaneous  \n",
      "2                                      Miscellaneous  \n",
      "3                               UI & User Experience  \n",
      "4  Account Access Issues, Transaction & Performan...  \n",
      "\n",
      "Theme distribution by bank:\n",
      "identified_themes            Account Access Issues  Bugs & Reliability  \\\n",
      "bank_name                                                                \n",
      "Bank of Abyssinia                               55                 132   \n",
      "Commercial Bank of Ethiopia                    287                 428   \n",
      "Dashen Bank                                     27                  16   \n",
      "\n",
      "identified_themes            Customer Support & Features  Miscellaneous  \\\n",
      "bank_name                                                                 \n",
      "Bank of Abyssinia                                     96            731   \n",
      "Commercial Bank of Ethiopia                          620           5580   \n",
      "Dashen Bank                                           62            274   \n",
      "\n",
      "identified_themes            Transaction & Performance  UI & User Experience  \n",
      "bank_name                                                                     \n",
      "Bank of Abyssinia                                  134                    48  \n",
      "Commercial Bank of Ethiopia                        874                   524  \n",
      "Dashen Bank                                        108                    75  \n",
      "\n",
      "Saving processed reviews with sentiment and themes to: c:\\Users\\hp\\OneDrive\\Desktop\\kaim-ai\\KAIM-2\\fintech-app-customer-experience-analytics\\data\\processed\\reviews_with_sentiment_themes.csv\n",
      "\n",
      "--Sentiment & Thematic Analysis Complete \n"
     ]
    }
   ],
   "source": [
    "# --- Step 4: Thematic Analysis (Keyword Extraction & Rule-Based Theming) ---\n",
    "print(\"\\n--- Performing Thematic Analysis ---\")\n",
    "\n",
    "# Initialize TF-IDF Vectorizer (after stopwords are handled in clean_text_nlp if you added it)\n",
    "# Make sure to handle empty strings for TfidfVectorizer\n",
    "tfidf_texts = df[df['cleaned_review_text'].str.strip() != '']['cleaned_review_text']\n",
    "\n",
    "if not tfidf_texts.empty:\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1,2)) # Consider unigrams and bigrams\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(tfidf_texts)\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "    print(f\"Top 10 TF-IDF keywords (overall):\")\n",
    "    # Get overall top keywords\n",
    "    sums_tfidf = tfidf_matrix.sum(axis=0)\n",
    "    features_scores = []\n",
    "    for col, term in enumerate(feature_names):\n",
    "        features_scores.append((term, sums_tfidf[0, col]))\n",
    "    sorted_features = sorted(features_scores, key=lambda x: x[1], reverse=True)\n",
    "    for i, (term, score) in enumerate(sorted_features[:10]):\n",
    "        print(f\"{term}: {score:.2f}\")\n",
    "else:\n",
    "    print(\"No non-empty texts for TF-IDF vectorization.\")\n",
    "\n",
    "# --- Step 5: Thematic Analysis using Rule-Based Classification ---\n",
    "\n",
    "# Define themes and associated keywords for simple rule-based classification\n",
    "themes_keywords = {\n",
    "    'Account Access Issues': ['login', 'account', 'access', 'otp', 'user id', 'password', 'face id'],\n",
    "    'Transaction & Performance': ['transfer', 'send', 'money', 'slow', 'fast', 'transaction', 'payment', 'loading'],\n",
    "    'UI & User Experience': ['interface', 'design', 'user friendly', 'easy', 'layout', 'ui', 'ux'],\n",
    "    'Bugs & Reliability': ['bug', 'crash', 'error', 'issue', 'problem', 'fix', 'stable', 'glitch'],\n",
    "    'Customer Support & Features': ['support', 'customer service', 'help', 'response', 'feature', 'request', 'update', 'fingerprint']\n",
    "}\n",
    "\n",
    "def assign_themes(review_text):\n",
    "    assigned = []\n",
    "    text_lower = str(review_text).lower()\n",
    "    for theme, keywords in themes_keywords.items():\n",
    "        if any(keyword in text_lower for keyword in keywords):\n",
    "            assigned.append(theme)\n",
    "    return assigned if assigned else ['Miscellaneous'] # Assign 'Miscellaneous' if no theme found\n",
    "\n",
    "print(\"\\nAssigning themes to reviews...\")\n",
    "df['identified_themes'] = df['cleaned_review_text'].apply(assign_themes)\n",
    "\n",
    "# Convert list of themes to a string for easier viewing\n",
    "df['identified_themes_str'] = df['identified_themes'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "\n",
    "print(\"\\nThematic Analysis Complete. First 5 rows with identified themes:\")\n",
    "print(df[['review_text', 'identified_themes_str']].head())\n",
    "\n",
    "print(\"\\nTheme distribution by bank:\")\n",
    "# To get a count of reviews per theme per bank, you'll need to expand the lists\n",
    "themes_exploded = df.explode('identified_themes')\n",
    "print(themes_exploded.groupby(['bank_name', 'identified_themes']).size().unstack(fill_value=0))\n",
    "\n",
    "# --- Save Results for Task 3 ---\n",
    "print(f\"\\nSaving processed reviews with sentiment and themes to: {SENTIMENT_THEMES_CSV}\")\n",
    "# Drop the original 'cleaned_review_text' and 'identified_themes' list column if you want a cleaner CSV\n",
    "df_to_save = df.drop(columns=['cleaned_review_text', 'identified_themes'])\n",
    "df_to_save.to_csv(SENTIMENT_THEMES_CSV, index=False)\n",
    "\n",
    "print(\"\\n--Sentiment & Thematic Analysis Complete \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6ca775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
